{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Set 2: Text classification\n",
    "==============\n",
    "(_This problem set is graded out of 50 for students taking CS4650 and out of 53 for students taking CS7650. But like all problem sets, this will count towards 8% of your final grade _)\n",
    "\n",
    "In this problem set, you will build a system for classifying book reviews on amazon as positive or negative. You will:\n",
    "\n",
    "- Do some basic text processing, tokenizing your input and converting it into a bag-of-words representation\n",
    "- Build a classifier based on sentiment word lists\n",
    "- Build a machine learning classifier based on the generative model, using Naive Bayes\n",
    "- Evaluate your classifiers and examine what they have learned\n",
    "- Build a machine learning classifier based on the discriminative model, using Perceptron\n",
    "- Build more stable discriminative classifier, using the averaged perceptron\n",
    "- Build the logistic regression classifier (See instructions within the section)\n",
    "- Implement techniques to improve your classifier\n",
    "- Participate in a hopefully fun bakeoff competition.\n",
    "\n",
    "**To turn in this project, please submit on T-square:**\n",
    "\n",
    "- this notebook\n",
    "- all files in the ```gtnlplib``` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set up\n",
    "\n",
    "In order to develop this assignment, you will have to install the following, if you don't have it already.\n",
    "\n",
    "- [python 2.7](https://www.python.org/downloads/release/python-2710/) (and not Python 3, although if somebody wants to try that and tell us what goes wrong, that would be appreciated...)\n",
    "- [jupyter notebook](http://jupyter.readthedocs.org/en/latest/install.html)\n",
    "- [scipy](http://www.scipy.org/install.html)\n",
    "- numpy (This will come if you install scipy like above, but if not install separately)\n",
    "- [nltk](http://www.nltk.org/install.html) (tested on NLTK 3.0.4)\n",
    "- [matplotlib](http://matplotlib.org/users/installing.html)\n",
    "- [nosetests](https://nose.readthedocs.org/en/latest/)\n",
    "\n",
    "You also need to get the data, which is available [here](https://github.com/jacobeisenstein/gt-nlp-class/releases/tag/amazon-fall-2015). Unzip this in the \"data\" directory of this project.\n",
    "\n",
    "\n",
    "** Notes **\n",
    "\n",
    "- The code with this assignment also contains test\\*.py files. These are used by nosetests which is one of python's framework to test your code. We will use these tests to help grade; you can run them too if you want. You can learn more about how to run them [here](http://pythontesting.net/framework/nose/nose-introduction/).\n",
    "- You are free to add more tests, but that is completely optional.\n",
    "- Jupyter runs in a web browser. You want to be careful about the text output from your code; if you try to output a huge amount of text, the browser will require a lot of memory, and so the notebook will become very slow and hard to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are also given some code to start with. As you progress, you will be writing the missing pieces in the code and/or implementing new code. All the code is in the ** gtnlplib ** directory which came as part of the assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import gtnlplib.preproc\n",
    "import gtnlplib.preproc_metrics\n",
    "\n",
    "import gtnlplib.clf_base\n",
    "import gtnlplib.wordlist\n",
    "import gtnlplib.naivebayes\n",
    "import gtnlplib.perceptron\n",
    "import gtnlplib.avg_perceptron\n",
    "import gtnlplib.logreg\n",
    "\n",
    "import gtnlplib.scorer\n",
    "import gtnlplib.constants\n",
    "import gtnlplib.analysis\n",
    "\n",
    "# this enables you to create inline plots in the notebook \n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While developing the modules of the library, it is likely that you make mistakes. If that happens, you correct the mistake and reload whichever modules you edited, as shown below. This is part of the python development cycle. If reloading doesn't work, restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(gtnlplib.preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Processing #\n",
    "(_Completing gtnlplib.preproc.docsToBOWs() - 3 pts, each question in Deliverable 1 is worth 1 pt_)\n",
    "\n",
    "Your first step is to write code that can apply the following\n",
    "preprocessing steps. You will have to run this code fairly quickly on\n",
    "the test data when you receive it, so make sure it is modular and\n",
    "well-written.\n",
    "\n",
    "- You will edit ```gtnlplib.preproc.docsToBOWs``` that takes as its argument a \"key\" document.\n",
    "  It should produce a \"BOW\" (bag-of-words) document.\n",
    "  Each line of the key document contains a filename and a label.\n",
    "  Each line of the BOW document should contain a BOW representation of the corresponding\n",
    "  file in the key document. \n",
    "- A BOW representation looks like this: \"word:count word:count word:count...\" for every word that appears in\n",
    "  the document. Do not print words that have zero count. Use space delimiters.\n",
    "- Use NLTK's [tokenization package](http://nltk.org/api/nltk.tokenize.html) function \n",
    "  to divide each file into sentences, and each sentence into tokens.\n",
    "- Downcase all tokens\n",
    "- Only consider tokens that are completely alphabetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TRAINKEY, DEVKEY and TESTKEY are defined in the gtnlplib.constants module\n",
    "\n",
    "gtnlplib.preproc.docsToBOWs(gtnlplib.constants.TRAINKEY)\n",
    "gtnlplib.preproc.docsToBOWs(gtnlplib.constants.DEVKEY)\n",
    "## uncomment once you have the test data\n",
    "#gtnlplib.preproc.docsToBOWs(gtnlplib.constants.TESTKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```gtnlplib.preproc``` module defines a [generator function](http://wiki.python.org/moin/Generators), called \"dataIterator\"\n",
    "\n",
    "- This allows you to easily iterate through the dataset defined by a given keyfile. \n",
    "- Each time you call \"next\" (possibly implicitly), it returns a dict containing features and counts for the next document in the sequence. \n",
    "- In this case, the features include the words, and a special \"offset\" feature\n",
    "- This is equivalent to $\\textbf{x}_i$ in the reading.\n",
    "- You can see how this is used in the getAllCounts() function below, which takes a dataIterator as an argument.\n",
    "\n",
    "\n",
    "Lines 7-8 of the code in the dataIterator function might look confusing if you are not a pythonista. \n",
    "\n",
    "- This is a [list comprehension](http://legacy.python.org/dev/peps/pep-0202/)\n",
    "nested inside a [dict comprehension](http://legacy.python.org/dev/peps/pep-0274/).\n",
    "- Here's an [introduction](http://carlgroner.me/Python/2011/11/09/An-Introduction-to-List-Comprehensions-in-Python.html) with more examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check**: How many unique words appear in the training set? (Types, not tokens.) In order to get this one correct you should pass the test \"test_number_of_tokens\"  in testpreproc.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ac_train = gtnlplib.preproc.getAllCounts(gtnlplib.preproc.dataIterator(gtnlplib.constants.TRAINKEY))\n",
    "ac_dev = gtnlplib.preproc.getAllCounts(gtnlplib.preproc.dataIterator(gtnlplib.constants.DEVKEY))\n",
    "print \"number of word types\",len(ac_train.keys())-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code makes a plot, with the log-rank (from 1 to the log of the total number of words) \n",
    "on the x-axis and the log count on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_logcounts = np.log(np.array(sorted(ac_train.values(),reverse=True)))\n",
    "plt.plot(np.log(range(len(tr_logcounts))),tr_logcounts)\n",
    "dv_logcounts = np.log(np.array(sorted(ac_dev.values(),reverse=True)))\n",
    "plt.plot(np.log(range(len(dv_logcounts))),dv_logcounts,'r')\n",
    "plt.xlabel('log rank')\n",
    "plt.ylabel('log count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1**\n",
    "\n",
    "(1 point each)\n",
    "\n",
    "- Explain what you see in the plot.\n",
    "- Print the token/type ratio for the training data.\n",
    "  You will have to implement ```gtnlplib.preproc_metrics.get_token_type_ratio```\n",
    "\n",
    "- Print the number of types which appear exactly once in the training data. These are called [hapax-legomena](https://en.wikipedia.org/wiki/Hapax_legomenon).\n",
    "  You will have to implement ```gtnlplib.preproc_metrics.type_frequency```\n",
    "\n",
    "- Print the number of types that appear in the dev data but not the training data (hint: use [sets](https://docs.python.org/2/library/sets.html) for this).\n",
    "  You will have to implement ```gtnlplib.preproc_metrics.unseen_types```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(add cells with your answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You will have to implement this function\n",
    "print 'tt-train', gtnlplib.preproc_metrics.get_token_type_ratio(ac_train) \n",
    "print 'tt-dev', gtnlplib.preproc_metrics.get_token_type_ratio (ac_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You will have to implement this function\n",
    "print 'tr-hapax-legomena',gtnlplib.preproc_metrics.type_frequency (ac_train, 1)\n",
    "print 'de-hapax-legomena',gtnlplib.preproc_metrics.type_frequency (ac_dev, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You will have to implement this function\n",
    "print 'unseen', gtnlplib.preproc_metrics.unseen_types (ac_train, ac_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basic classification #\n",
    "(_Completing predict() - 3 pts_)\n",
    "\n",
    "To get started, we build a simple classifier, which labels all instances as positive. \n",
    "This is the \"most common class\" (MCC) baseline. \n",
    "Take a look at the implementation to see how the weights are stored and set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_mcc = gtnlplib.wordlist.learnMCCWeights ()\n",
    "print weights_mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use these weights in a classifier, you need to complete ```gtnlplib.clf_base.predict```, which represents the inner-product computation ${\\theta}' \\textbf{f}(\\textbf{x},y)$.\n",
    "It should have the following characteristics:\n",
    "\n",
    "- **Input 1** an instance, represented as a dict (with features as keys and counts as values) \n",
    "- **Input 2** a dictionary of weights, where keys are tuples of features and labels, and weights are the values. This corresponds to ${\\theta}$ in the reading. See example below.\n",
    "- **Input 3** a list of possible candidate class labels\n",
    "- **Output 1** the highest-scoring label\n",
    "- **Output 2** a dict with labels as keys and scores as values\n",
    "\n",
    "Then you can call ```gtnlplib.clf_base.evalclassifier``` to compute accuracy. The relevant tests are testwlc.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outfile = 'all_pos.txt'\n",
    "mat = gtnlplib.clf_base.evalClassifier(weights_mcc,outfile, gtnlplib.constants.DEVKEY)\n",
    "print gtnlplib.scorer.printScoreMessage(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check**: You should get 37.56% accuracy just by classifying everything as positive. \n",
    "\n",
    "- The printed output is a **confusion matrix**. \n",
    "- The rows indicate the key and the columns indicate the response. \n",
    "- In this case, the response is always \"POS\", so there is only one column. \n",
    "- The cell NEG/POS tells you how often an example that was labeled \"NEG\" in the key was labeled \"POS\" in the system response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Word list classification #\n",
    "(_setting weights - 2 pts, Deliverable 3 - 1 pt. Total 3 pts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will now build a sentiment analysis system based on word lists. \n",
    "- The file \"data/sentiment-vocab.tff\" contains a sentiment lexicon from [ Wilson et al 2005](http://people.cs.pitt.edu/~wiebe/pubs/papers/emnlp05polarity.pdf). \n",
    "- The provided function ```gtnlplib.wordlist.loadSentimentWords``` reads the lexicon into memory, building sets of positive and negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poswords, negwords = gtnlplib.wordlist.loadSentimentWords (gtnlplib.constants.SENTIMENT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a classifier that classifies each instance in a testfile. The classification rule is:\n",
    "\n",
    "- 'POS' if the instance has more words from the positive list than the negative list\n",
    "- 'NEG' if the instance has more words from the negative list than the positive list\n",
    "- 'NEU' (neutral) if the instance has the same number of words from each list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 3**: run your classifier on dev.key, and use the following code to print the resulting confusion matrix. For this you will have to implement ```gtnlplib.wlclf.learnWLCWeights``` function based on the instructions given earlier in the section.\n",
    "\n",
    "The confusion matrix should now have three columns, since the response should include every class at least once. The count of correct responses is found on the diagonal of the confusion matrix. What is the most frequent type of error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_wlc = gtnlplib.wordlist.learnWLCWeights (poswords, negwords)\n",
    "outfile = 'word_list.txt'\n",
    "mat = gtnlplib.clf_base.evalClassifier(weights_wlc,outfile, gtnlplib.constants.DEVKEY)\n",
    "print gtnlplib.scorer.printScoreMessage(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Naive Bayes #\n",
    "(_Completing learnNBWeights() - 5 pts, Deliverable 4a - 1pt, 4b - 1 pt, explanation of plot output - 2pts. Total 8 points_)\n",
    "\n",
    "Now you will implement a Naive Bayes classifier.\n",
    "\n",
    "You already have the code for the decision function, \"predict\". \n",
    "So you just need to construct a set of weights that correspond to the classifier. \n",
    "These weights will contain two parameters:\n",
    "\n",
    "- $\\log \\mu$ for the offset, which parametrizes the prior $\\log P(y)$\n",
    "- $\\log \\phi$ for the word counts, which parametrizes the likelihood $\\log P(x | y)$\n",
    "\n",
    "You should use maximum *a posteriori* estimation of\n",
    "the parameter $\\phi$,\n",
    "$$\\phi_{j,n} = P(w = n | y = j) = \\frac{\\sum_{i: y_i = j} x_{i,n} + \\alpha}{\\sum_{i:y_i=j} \\sum_{n'} x_{i,n'} + V\\alpha}$$\n",
    "where \n",
    "\n",
    "- $y_i = j$ indicates the class label $j$ for instance $i$\n",
    "- $w=n$ indicates word $n$\n",
    "- $\\alpha$ is the smoothing parameter\n",
    "- $V$ is the total number of words\n",
    "\n",
    "For each class, normalize by the sum of counts of words **in that class**. In other words, $\\sum_n \\phi_{j,n} = 1$ for all $j$. You can estimate $\\log \\phi$ directly if you prefer.\n",
    "\n",
    "For the prior $\\log P(y)$, you can use relative frequency estimation.\n",
    "\n",
    "Both probabilities should be estimated from the training data only.\n",
    "Please write this code yourself -- do not use other libraries, and try to do\n",
    "it without looking at other code online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First call ```gtnlplib.preproc.getCountsAndKeys```, which returns the following objects:\n",
    "\n",
    "- word counts for every label in the training data.\n",
    "- the count of instances with every label in the training data.\n",
    "- a list of all word types that are observed in the training data\n",
    "\n",
    "You want to do this once, because computing these counts is slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts, class_counts,allkeys = gtnlplib.preproc.getCountsAndKeys(gtnlplib.constants.TRAINKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will first have to implement ```gtnlplib.naivebayes.learnNBWeights```, and then run it to get the weights of the naive bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_nb = gtnlplib.naivebayes.learnNBWeights (counts, class_counts, allkeys, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check**: the word probabilities for each class should sum to 1, or very close:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sanity check!\n",
    "sum([np.exp(weights_nb[('POS',basefeat)]) for basefeat in allkeys if basefeat != gtnlplib.constants.OFFSET])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 4a**\n",
    "Train your classifier from the training data, and apply it to\n",
    "the development data, with $\\alpha = 0.1$. Report the confusion matrix and the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outfile = 'nb.txt'\n",
    "mat = gtnlplib.clf_base.evalClassifier(weights_nb,outfile, gtnlplib.constants.DEVKEY)\n",
    "print gtnlplib.scorer.printScoreMessage(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 4b** Try at least seven different values of $\\alpha$. Plot the accuracy on both the dev and training sets for each value, using [subplot](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.subplot) to show two plots in the same cell.The values of $\\alpha$ should be chosen such that the max value is not at either endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas = [] #your choice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_nb_alphas, tr_accs, dv_accs = gtnlplib.naivebayes.regularization_using_grid_search (alphas,counts, class_counts, allkeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,alpha in enumerate (alphas):\n",
    "    print alpha, tr_accs[i], dv_accs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run this code to plot the accuracies\n",
    "subplot(1,2,1)\n",
    "plot(log(alphas),tr_accs,'bx-') \n",
    "ylabel('training accuracy')\n",
    "subplot(1,2,2)\n",
    "plot(log(alphas),dv_accs,'rx-')\n",
    "ylabel('dev. accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Use this cell to explain what you see in the plot above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature Analysis #\n",
    "(_Completing  getTopFeats() - 2 pts, Deliverable 5a - 1pt, 5b - 2 pts . Total 5 pts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 5a**\n",
    "What are the words that are most predictive of positive versus negative text?\n",
    "You can measure this by $\\log \\theta_{pos,n} - \\log \\theta_{neg,n}$ (which is similar to the [likelihood ratio test](http://en.wikipedia.org/wiki/Likelihood-ratio_test)).\n",
    "Use $\\alpha = 0.1$.\n",
    "\n",
    "List the top five words and their counts for each class. Do the same for the top 5 words that predict negative versus positive.\n",
    "\n",
    "** Note **\n",
    "\n",
    "- You will have to implement ```gtnlplib.analysis.getTopFeats```. \n",
    "- You may need to sort dictionaries for getting the top features. Consider using [operator.itemgetter()](http://docs.python.org/2.7/library/operator.html) to easily sort dictionaries by their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print gtnlplib.analysis.getTopFeats(weights_nb_alphas[1e-1],'POS','NEG',allkeys)\n",
    "print gtnlplib.analysis.getTopFeats(weights_nb_alphas[1e-1],'NEG','POS',allkeys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 5b** Now do the same thing for $\\alpha = 10$. Which words look better to you? \n",
    "Which gave better accuracy? \n",
    "Explain what you think is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print gtnlplib.analysis.getTopFeats(weights_nb_alphas[10],'POS','NEG',allkeys)\n",
    "print gtnlplib.analysis.getTopFeats(weights_nb_alphas[10],'NEG','POS',allkeys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Perceptron #\n",
    "(_ 6 points total _)\n",
    "\n",
    "Implement a perceptron classifier. Using the feature-function\n",
    "representation, include features for each word-class pair, and also an\n",
    "** offset ** feature for each class. Given a set of word counts $\\vec{x}_i$,\n",
    "a true label $y_i$, and a guessed label $\\hat{y}$, your update will be\n",
    "\\begin{align*}\n",
    "\\hat{y} & \\leftarrow \\text{argmax}_y \\vec{\\theta}' f(\\vec{x}_i,y)\\\\\n",
    "\\vec{\\theta} & \\leftarrow \\vec{\\theta} + f(\\vec{x}_i, y_i) - f(\\vec{x}_i, \\hat{y}).\n",
    "\\end{align*}\n",
    "\n",
    "Please write this yourself -- do not use any libraries, and try not to look\n",
    "at other code online.\n",
    "\n",
    "**Sanity check** If you are not careful, learning can be slow. \n",
    "You may need to think a little about how to do this update efficiently. \n",
    "\n",
    "- On my laptop, I can make 10 passes on the training data in roughly 30 seconds, including evaluating the accuracy on the dev and training sets. \n",
    "- You can use the ```%%timeit``` cell magic to compute statistics like this.\n",
    "- Your code doesn't have to be as fast as mine, but it needs to be written intelligently, and it needs to be fast enough for you to debug it properly.\n",
    "- The ```%%prun``` cell magic is also useful for diagnosing speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with we will load all the training data: the training set and the development. This will increase the speed. ```gtnlplib.preproc.loadInstances``` implementation is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tr_insts,all_dev_insts= gtnlplib.preproc.loadInstances(gtnlplib.constants.TRAINKEY, gtnlplib.constants.DEVKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 6a** (5 points)\n",
    "\n",
    "Implement the function ```gtnlplib.perceptron.oneItPerceptron``` that runs the perceptron for a single iteration (one pass through the training data). Its signature should be:\n",
    "\n",
    "- **Input 1**: all training instances\n",
    "- **Input 2**: a dictionary of weights, representing the current classifier at the time you call this function\n",
    "- **Input 3**: a list of all possible labels\n",
    "- **Output 1**: the weights after training\n",
    "- **Output 2**: the number of training errors\n",
    "- **Output 3**: the number of training instances\n",
    "\n",
    "The second and third outputs allow you to compute the *training set accuracy*. This way, you can see whether you are overfitting or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 6b** (1 point): Train your classifier on trainkey for ten iterations, and plot the output. For this you will have to implement ```gtnlplib.perceptron.trainPerceptron``` function making use of ```gtnlplib.perceptron.oneItPerceptron``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outfile = \"perc.txt\"\n",
    "w_perc,tr_acc_perc,dv_acc_perc = gtnlplib.perceptron.trainPerceptron(10, all_tr_insts,gtnlplib.constants.ALL_LABELS, outfile, gtnlplib.constants.DEVKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this code makes plots of the training and development set accuracy\n",
    "def makePlots(tr_acc,dv_acc):\n",
    "    ax1 = plt.subplot(1,2,1,xlabel='iteration',ylabel='accuracy')\n",
    "    plt.plot(tr_acc,'rx-')\n",
    "    plt.title('training')\n",
    "    plt.subplot(1,2,2,xlabel='iterator',sharey=ax1)\n",
    "    plt.plot(dv_acc,'bx-')\n",
    "    plt.title('development')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "makePlots(tr_acc_perc,dv_acc_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check** Your training set accuracy should increase quickly, but your dev set accuracy might be disappointing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Averaged Perceptron #\n",
    "\n",
    "Notice how the dev set performance of the perceptron was very unstable. Now you will try to improve it using averaging.\n",
    "\n",
    "Conceptually, the idea is to keep a running total of the weights, and then divide at the end, after $T$ updates:\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{y} & \\leftarrow \\text{argmax}_y \\theta' f(\\vec{x}_i,y)\\\\\n",
    "\\theta^t & \\leftarrow \\theta^{t-1} + f(\\vec{x}_i, y_i) - f(\\vec{x}_i, \\hat{y})\\\\\n",
    "\\overline{\\theta} & = \\frac{1}{T} \\theta^T\n",
    "\\end{align*}\n",
    "\n",
    "Then you can use $\\overline{\\theta}$ to make predictions.\n",
    "\n",
    "But in practice, this is very inefficient. You can't store the weights after every update -- it's much too big. But you don't want to compute a running sum either. The reason is that the weight vector will quickly become dense, and this would require $O(\\#F)$ operations at every update, where $\\#F$ is the number of features. This is much more work than the standard perceptron update, which only involves the features that are active in the current instance. In a bag-of-words model, each document will typically have only a small fraction of the total vocabulary, and we would like each update to be linear in the number of features active in the document, not the total number of features.\n",
    "\n",
    "An efficient solution was pointed out by [Daume 2006](http://hal3.name/docs/daume06thesis.pdf). \n",
    "Let $\\delta_t$ indicate the update at time $t$.\n",
    "Then, assuming $\\theta^0 = 0$, we have:\n",
    "\n",
    "\\begin{align*}\n",
    "\\theta^t = & \\theta^{t-1} + \\delta_t \\\\\n",
    "= & \\sum_{t' < t} \\delta_{t'}\n",
    "\\end{align*}\n",
    "\n",
    "We would like to compute the sum of the weight vectors,\n",
    "\\begin{align*}\n",
    "\\sum_t^T \\theta_t = & \\sum_t^T \\sum_{t' \\leq t} \\delta_{t'} = T \\delta_0 + (T-1) \\delta_1 + (T - 2) \\delta_2 + \\ldots + \\delta_T \\\\ \n",
    "= & \\sum_t^T (T - t) \\delta_t\\\\\n",
    "= & T \\sum_t^T \\delta_t - \\sum_t^T t \\delta_t \\\\\n",
    "= & T \\theta_t - \\sum_t^T t \\delta_t \\\\\n",
    "\\frac{1}{T} \\sum_t^T \\theta_t = & \\theta_T - \\frac{1}{T} \\sum_t^T t \\delta_t\n",
    "\\end{align*}\n",
    "\n",
    "This means we need to keep another running sum, $\\sum_t^T t \\delta_t$, the sum of scaled updates. \n",
    "To compute the average, we divide by the number of updates $T$ and subtract it from the current weight vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 7a** (5 points) Implement averaged perceptron, using two functions\n",
    "\n",
    "- an outer loop, ```gtnlplib.avg_perceptron.trainAvgPerceptron```, which should have the same inputs and outputs as  ```gtnlplib.perceptron.trainPerceptron```.\n",
    "- an inner loop, ```gtnlplib.avg_perceptron.oneItAvgPerceptron```, which makes a single pass through the training data. To do weight averaging, this function may have to take some additional arguments and offer some additional outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of implementation, your function ```gtnlplib.avg_perceptron.oneItAvgPerceptron``` should be similar to ```gtnlplib.perceptron.oneItPerceptron```, but it needs to take additional arguments to keep track of the running sum of weights, and the total number if instances seen.  It also needs to output this information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 7b** (1 point): Train your classifier on trainkey for ten iterations, and plot the output, using the code in the cells below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(gtnlplib.avg_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# again, this takes roughly 30 seconds for me\n",
    "outfile = \"ap.txt\"\n",
    "w_ap,tr_acc_ap,dv_acc_ap = gtnlplib.avg_perceptron.trainAvgPerceptron(10,all_tr_insts,gtnlplib.constants.ALL_LABELS, outfile,gtnlplib.constants.DEVKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "makePlots(tr_acc_ap,dv_acc_ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check** the dev set performance should be much better than the non-averaged perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 7c** (1 point) Use your getTopFeats function from pset 1a to compute the top ten features for positive and negative classes, by contrasting the weights $\\theta_{pos,n} - \\theta_{neg,n}$ and $\\theta_{neg,n} - \\theta_{pos,n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print gtnlplib.analysis.getTopFeats(w_ap,'POS','NEG',allkeys, K=10)\n",
    "print gtnlplib.analysis.getTopFeats(w_ap,'NEG','POS',allkeys, K=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Logistic regression #\n",
    "\n",
    "Now you will complete an implementation of logistic regression.\n",
    "We've provided a lot of scaffolding code, you just need to fill in some key parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 8a** (3 points): implement ```gtnlplib.logreg.computeLabelProbs``` to compute the normalized probability of each label.\n",
    "\n",
    "- This function should have the same input arguments as your predict function\n",
    "- It should output a dict, from labels to probabilities\n",
    "- It will need to be fast. You may need to optimize this later. As always, ```%%prun``` and ```%%timeit``` are your friends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sanity check**: running the code below should give\n",
    "\n",
    "- 'NEG': 0.0068674111043921151,\n",
    "- 'NEU': 0.37494794181688146,\n",
    "- 'POS': 0.61818464707872656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = defaultdict(float)\n",
    "weights[('NEG','bad')] = 1\n",
    "weights[('NEG','best')] = -1\n",
    "weights[('POS','bad')] = -0.5\n",
    "weights[('POS','best')] = 2\n",
    "weights[('NEU',gtnlplib.constants.OFFSET)] = 3\n",
    "gtnlplib.logreg.computeLabelProbs({'bad':1,'best':2,gtnlplib.constants.OFFSET:1},weights,gtnlplib.constants.ALL_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 8b** (3 points) Now complete the implementation of logistic regression, training by stochastic gradient descent.\n",
    "\n",
    "- An outline of the code is provided in ```gtnlplib.logreg.trainLRbySGD```, including the regularization\n",
    "- You need to provide the code that computes the update for each instance\n",
    "- My implementation takes around 3 seconds per iteration over the training set\n",
    "- Unlike the perceptron code, you can do everything within the single function ```gtnlplib.logreg.trainLRbySGD```\n",
    "- For a reminder about how SGD works, see my notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outfile = \"sgd.txt\"\n",
    "w_sgd,tr_acc_sgd,dv_acc_sgd = gtnlplib.logreg.trainLRbySGD(50,all_tr_insts, outfile, gtnlplib.constants.DEVKEY, regularizer=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "makePlots(tr_acc_sgd,dv_acc_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Making it better #\n",
    "\n",
    "There are two general paths for improving these classifiers: data and algorithms.\n",
    "\n",
    "- Data-oriented approaches relate to the features. For example, you could try to use bigrams, remove stopwords, lemmatize (using wordnet), etc.\n",
    "- Algorithm-oriented approaches relate to the learning itself. For example, you could implement Passive-Aggressive, AdaGrad (described in my notes), feature hashing (see [this paper](http://alex.smola.org/papers/2009/Weinbergeretal09.pdf)), alternative regularizers, or various improvements to naive bayes (see [this paper](http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf)). Note that not all these approaches will improve accuracy; some will improve speed.\n",
    "- Students in 4650 should try one improvement of either type. Students in 7650 should try one improvement of each type, and for at least one of the improvements, they should cite a specific research paper that motivated their choice. The paper should be from ACL, NAACL, EMNLP, ICML, NIPS, AAAI, or a similar journal.\n",
    "\n",
    "**Deliverable 9** (3 points for 4650; 6 points for 7650): Clearly explain what you did, and why you thought it would\n",
    "work. Do an experiment to test whether it works. Creativity and thoughtfulness counts more than raw performance here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Bakeoff! #\n",
    "\n",
    "48 hours before the assignment is due, I will send you unlabeled test\n",
    "data. Your job is to produce a response file, and submit it to our Kaggle\n",
    "bakeoff ([link here](https://inclass.kaggle.com/c/gt-book-review-sentiment-analysis)).\n",
    "The Kaggle contest compares your classifier's results on the dev data to generate a\n",
    "class-visible leaderboard, and compares your classifier's results on the unlabeled\n",
    "test data for the bakeoff. You can use the dev data results as a sanity\n",
    "check, to make sure you submit the correct file.\n",
    "\n",
    "I'll present the results in class and give the best scorers a chance to explain\n",
    "what they did.\n",
    "\n",
    "** Deliverable 10 ** (3 points) Run your best system from any part of the\n",
    "assignment on the test data using the `generateKaggleSubmission()` function. Submit\n",
    "your response file to the class [Kaggle bakeoff](https://inclass.kaggle.com/c/gt-book-review-sentiment-analysis). Also submit your Kaggle response file to T-Square as 'lastname-firstname.response'. The top\n",
    "scores will be announced in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yourBestWeights = weights_mcc # Change this to your best model\n",
    "gtnlplib.clf_base.generateKaggleSubmission(yourBestWeights, 'lastname-firstname.response')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
