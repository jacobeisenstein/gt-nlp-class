# 3.1 (0.5 points)

Fill in the rest of the table below:

|      | they | can | can | fish | END |
|------|------|-----|-----|------|-----|
| Noun | -2   |     |     |      | n/a |
| Verb | -13  |     |     |      | n/a |
| End  | n/a  | n/a | n/a | n/a  | -17 |


# 4.3 (0.5 points)

Do you think the predicted tags "PRON AUX AUX NOUN" for the sentence "They can can fish" are correct? Use your understanding of parts-of-speech from the notes.

# 4.4 (0.5 points)

The HMM weights include a weight of zero for the emission of unseen words. Please explain:

- why this is a violation of the HMM probability model explained in the notes;
- How, if at all, this will affect the overall tagging.

# 5.1 (1 point 4650; 0.5 points 7650)

Please list the top three tags that follow verbs and nouns in English and Japanese.

Try to explain some of the differences that you observe, making at least two distinct points about differences between Japanese and English.

# 6 (7650 only; 1 point)

Find an example of sequence labeling for a task other than part-of-speech tagging, in a paper at ACL, NAACL, EMNLP, EACL, or TACL, within the last five years (2012-2017). 

## List the title, author(s), and venue of the paper.

## What is the task they are trying to solve?

## What tagging methods do they use? HMM, CRF, max-margin markov network, something else?

## Which features do they use?

## What methods and features are most effective?
